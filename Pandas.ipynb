{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML.Expt2_changed.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVimIVKor-2u",
        "colab_type": "text"
      },
      "source": [
        "**Experiment No. 02**\n",
        "\n",
        "---\n",
        "\n",
        "**Aim:**Using Scipy Library.\n",
        "---\n",
        "\n",
        "**Objectives:**\n",
        "\n",
        "* Reading the Data\n",
        "* PreProcessing and cleaning the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3botqaEhunsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC0bkvEyczIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MlQ-wRqRN8E",
        "colab_type": "text"
      },
      "source": [
        "SciPy is a collection of mathematical algorithms and convenience functions built on the NumPy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. With SciPy, an interactive Python session becomes a data-processing and system-prototyping environment rivaling systems, such as MATLAB, IDL, Octave, R-Lab, and SciLab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIioEhaARUDg",
        "colab_type": "text"
      },
      "source": [
        "Reading Data Using Scipy\n",
        "\n",
        "We can read only MATLAB files using scipy.io library. There are three options to do that \n",
        "i.e \n",
        "\n",
        "\n",
        "loadmat(file_name[, mdict, appendmat])   -  Load MATLAB file.\n",
        "\n",
        "savemat(file_name, mdict[, appendmat, â€¦])  -  Save a dictionary of names and arrays into a MATLAB-style .mat file.\n",
        "\n",
        "whosmat(file_name[, appendmat]) - List variables inside a MATLAB file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWHIV7hcuui4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect = np.arange(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1UdAv8WvFoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sio.savemat('np_vector.mat', {'vect':vect})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1717SFx1vun6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat_contents = sio.loadmat('np_vector.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Bfq8Cmwdjg",
        "colab_type": "code",
        "outputId": "b82edac1-66ae-4217-b100-64318cddd136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "mat_contents['vect']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xst7yaETSGWs",
        "colab_type": "text"
      },
      "source": [
        "PREPROCESSING THE DATA\n",
        "\n",
        "Pre-processing refers to the transformations applied to our data before feeding it to the algorithm. Data Preprocessing is a technique that is used to convert the raw data into a clean data set. In other words, whenever the data is gathered from different sources it is collected in raw format which is not feasible for the analysis. For achieving better results from the applied model in Machine Learning projects the format of the data has to be in a proper manner. Some specified Machine Learning model needs information in a specified format, for example, Random Forest algorithm does not support null values, therefore to execute random forest algorithm null values have to be managed from the original raw data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfbVpANoxra9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas \n",
        "from sklearn.preprocessing import MinMaxScaler "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xPx-0jdxtYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Zz5ztlStac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pandas.read_csv('diabetes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVm5pVjuS8KO",
        "colab_type": "code",
        "outputId": "080584f9-9a8f-4267-c26f-1f41587d37eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "array = dataframe.values\n",
        "array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8EdzulkWwqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = array[:,1:8] \n",
        "Y = array[:,8] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-HMCS0UW1rS",
        "colab_type": "text"
      },
      "source": [
        "RESCALING THE DATA\n",
        "\n",
        "\n",
        "When our data is comprised of attributes with varying scales, many machine learning algorithms can benefit from rescaling the attributes to all have the same scale. This is useful for optimization algorithms in used in the core of machine learning algorithms like gradient descent. It is also useful for algorithms that weight inputs like regression and neural networks and algorithms that use distance measures like K-Nearest Neighbors. We can rescale your data using scikit-learn using the MinMaxScaler class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTQqxOCtW8_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APNzWGVVXA8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rescaledX = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-M49Z0iXGxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_gxRIm7XHfo",
        "colab_type": "code",
        "outputId": "075d0648-4b35-4a26-f77a-0b0744f7d090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "print(rescaledX[0:5,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
            " [0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
            " [0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
            " [0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
            " [0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnBP7NJdXLll",
        "colab_type": "text"
      },
      "source": [
        "BINARIZE THE DATA\n",
        "\n",
        "We can transform our data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0. This is called binarizing your data or threshold your data. It can be useful when you have probabilities that you want to make crisp values. It is also useful when feature engineering and you want to add new features that indicate something meaningful. We can create new binary attributes in Python using scikit-learn with the Binarizer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5naJMBRuXJj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Binarizer "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5sO_WuIXULZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binarizer = Binarizer(threshold=0.01).fit(X) \n",
        "binaryX = binarizer.transform(X) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig_FKKMQXUoR",
        "colab_type": "code",
        "outputId": "03d1a3c3-9950-4d1a-84ef-d91c268df8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "print(binaryX[0:5,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 0. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIeT48cmXYUy",
        "colab_type": "text"
      },
      "source": [
        "Standardizing the data:\n",
        "\n",
        "Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. We can standardize data using scikit-learn with the StandardScaler class.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-bXLx93XfOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBRlt6ZgXkJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler().fit(X) \n",
        "rescaledX = scaler.transform(X) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2pgnEr9XoFY",
        "colab_type": "code",
        "outputId": "79dd7ef8-4df3-40ce-adb2-30faa5a6c210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "print(rescaledX[0:5,:]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
            " [-1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
            " [ 1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
            " [-0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
            " [ 0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYmSTmyMYAKa",
        "colab_type": "text"
      },
      "source": [
        "Conclusion\n",
        "\n",
        "In this experiment we studied how to read files using scipy library and the various ways we can preprocess the data using sklearn from the scipy library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86T8KlKlYFA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}